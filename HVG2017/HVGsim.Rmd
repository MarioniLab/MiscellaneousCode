---
title: Simulating various types of HVGs 
author: Aaron Lun
date: 26 January 2017
output:
  html_document:
    fig_caption: false 
---

```{r, echo=FALSE, results="hide"}
dir.create("figure-hvg", showWarning=FALSE)
knitr::opts_chunk$set(error=FALSE, warning=FALSE, message=FALSE, fig.path="figure-hvg/")
options(width=100)
```

# Introduction

This simulation describes various types of HVGs and the relative capabilities of different HVG detection methods to, well, detect them.
Firstly, setting up a function to generate gene expression values for non-HVGs.

```{r}
nsamples <- 1000   
computeDisp <- function(means) {
    10/means + 0.2
}
standardSetup <- function(ngenes, nspikes) { 
    total.genes <- ngenes + nspikes 
    means <- 2^runif(total.genes, -2, 10) 
    dispersions <- computeDisp(means)
    counts <- matrix(rnbinom(total.genes*nsamples, mu=means, size=1/dispersions), ncol=nsamples) 
    is.spike <- logical(total.genes) 
    is.spike[seq_len(nspikes)] <- TRUE 
    return(list(counts=counts, is.spike=is.spike)) 
} 
```

# Genes involved in trajectories

Setting up the standard counts first.

```{r}
library(scran)
set.seed(100)
sim <- standardSetup(1000, 100)
counts <- sim$counts
is.spike <- sim$is.spike
```

Adding some substructure - in this case, a trajectory.
This involves different genes going from a count of 1 to 50-1000.

```{r}
affect <- 20
mu.values <- matrix(1:nsamples, ncol=nsamples, nrow=affect, byrow=TRUE)/(affect:1)
disp.values <- computeDisp(mu.values)
to.change <- sum(is.spike)+1:affect
counts[to.change,] <- rnbinom(length(mu.values), mu=mu.values, size=1/disp.values)
```

`technicalCV2` only picks up few of the HVGs.
This might be due to a continuum where the variance just can't get particularly large (compared to bimodal expression patterns).
It gets better if you turn off `min.bio.disp`, but that also increases the background.

<!--
12/51, and 20/84
-->

```{r cv2plotter}
out <- technicalCV2(counts, is.spike, sf.cell=1, sf.spike=1)
plot(out$mean, out$cv2, log="xy")
points(out$mean, out$trend, col="red", pch=16, cex=0.5)
is.sig <- which(out$FDR <= 0.05 & !is.na(out$FDR))
length(intersect(is.sig, to.change))
length(is.sig)
out <- technicalCV2(counts, is.spike, sf.cell=1, sf.spike=1, min.bio.disp=0)
is.sig <- which(out$FDR <= 0.05 & !is.na(out$FDR))
length(intersect(is.sig, to.change))
length(is.sig)
```

Log-variances picks up all of the HVGs but none of the noise, with a relatively small increase in background upon losing `bio > 0.5`.

<!--
20/20 and 20/27
-->

```{r logplotter}
lcounts <- log2(counts+1)
fit <- trendVar(lcounts[is.spike,], span=0.2)
ref <- decomposeVar(lcounts, fit)
plot(ref$mean, ref$total)
curve(fit$trend(x), add=TRUE, col='red')
is.sig <- which(ref$FDR <= 0.05 & !is.na(ref$FDR) & ref$bio > 0.5)
length(intersect(is.sig, to.change))
length(is.sig)
is.sig <- which(ref$FDR <= 0.05) 
length(intersect(is.sig, to.change))
length(is.sig)
```

The `improvedCV2` method also gives reasonably good results, presumably because type I error control is better than in `technicalCV2`.

<!--
20/39
-->

```{r icv2plotter}
out <- improvedCV2(counts, is.spike, sf.cell=1, sf.spike=1)
plot(out$mean, out$cv2, log="xy")
points(out$mean, out$trend, col="red", pch=16, cex=0.5)
is.sig <- which(out$FDR <= 0.05 & !is.na(out$FDR))
length(intersect(is.sig, to.change))
length(is.sig)
```

# Genes involved in clustering

Setting up the standard genes again.

```{r}
set.seed(200)
sim <- standardSetup(1000, 100)
counts <- sim$counts
is.spike <- sim$is.spike
```

Adding some substructure - in this case, some clusters, by doubling expression in the first half of cells.

```{r}
to.change <- sum(is.spike) + 1:50
counts[to.change,1:500] <- counts[to.change,1:500] * 2
```

Few of the HVGs are picked up with the CV^2^ method, again presumably because the `min.bio.disp` argument overwhelms the actual increase in the CV^2^.
Turning it off improves detection but also carries a lot of extra noise with it.

<!--
17/56, and 48/141
-->

```{r, ref.label="cv2plotter"}
```

A similar number get picked up, but with less background, in the log-variance method.
Dropping the requirement for `bio > 0.5` results in more detection with a little increase in background.

<!--
17/17, and 47/47
-->

```{r, ref.label="logplotter"}
```

There is also less background in the improved method:

<!--
44/46
-->

```{r ref.label="icv2plotter"}
```


# Genes in rare populations

## Upregulated in the rare population

Now testing for genes that are upregulated in a rare subpopulation.

```{r}
set.seed(300)
sim <- standardSetup(5000, 500)
counts <- sim$counts
is.spike <- sim$is.spike
```

Adding some genes only present in a small (1%) subpopulation.

```{r}
to.change <- sum(is.spike) + 1:500
rare.means <- 1:500*20
rare.disp <- computeDisp(rare.means)
nrare <- nsamples/100
counts[to.change,] <- 0L
counts[to.change,1:nrare] <- rnbinom(nrare*length(rare.means), mu=rare.means, size=1/rare.means)
```

The CV^2^ method can detect these changes at a count of ~10.
This makes sense as the CV^2^ method is highly sensitive to large outliers, which inflate the variance without increasing the mean as much.

<!--
16/250
-->

```{r}
out <- technicalCV2(counts, is.spike, sf.cell=1, sf.spike=1)
plot(out$mean, out$cv2, log="xy")
points(out$mean, out$trend, col="red", pch=16, cex=0.5)
rare.sig <- intersect(to.change, which(out$FDR <= 0.05)) 
rare.means[rare.sig - sum(is.spike)]
length(rare.sig)
sum(out$FDR <= 0.05, na.rm=TRUE)
```

We repeat the dose for the improved CV^2^ method, which is also able to detect these genes quite well without so much of the background:

<!--
16/71
-->

```{r}
out <- improvedCV2(counts, is.spike, sf.cell=1, sf.spike=1)
plot(out$mean, out$cv2, log="xy")
points(out$mean, out$trend, col="red", pch=16, cex=0.5)
rare.sig <- intersect(to.change, which(out$FDR <= 0.05)) 
rare.means[rare.sig - sum(is.spike)]
length(rare.sig)
sum(out$FDR <= 0.05, na.rm=TRUE)
```

An even greater reduction in background is observed with the log-variance method.
However, the log-transformation squishes the highly expressing genes downward and reduces the biological component, so you don't get anything with `bio > 0.5`.
Even if the log-fold changes between subpopulations is strong, the average squared difference across all cells would be low when one subpopulation is rare.

<!--
16/47 and 0/0
-->

```{r}
lcounts <- log2(counts+1)
fit <- trendVar(lcounts[is.spike,], span=0.2)
ref <- decomposeVar(lcounts, fit)
plot(ref$mean, ref$total)
curve(fit$trend(x), col="red", add=TRUE)
rare.sig <- intersect(to.change, which(ref$FDR <= 0.05)) 
rare.means[rare.sig - sum(is.spike)]
length(rare.sig)
sum(ref$FDR <= 0.05, na.rm=TRUE)
rare.sig <- intersect(to.change, which(ref$FDR <= 0.05 & ref$bio > 0.5)) 
rare.means[rare.sig - sum(is.spike)]
length(rare.sig)
sum(ref$FDR <= 0.05 & ref$bio > 0.5, na.rm=TRUE)
```

## Downregulated in the rare population

What about genes going in the other direction?
First, setting up the standard set.

```{r}
set.seed(100)
sim <- standardSetup(5000, 500)
counts <- sim$counts
is.spike <- sim$is.spike
```

Adding some genes that are exclusively silent in a small (1%) subpopulation.

```{r}
to.change <- sum(is.spike) + 1:500
counts[to.change,1:nrare] <- 0
```

CV^2^ detects a few, presumably because loss of expression doesn't make a big dent on the CV^2^ when the mean is already large.
To illustrate, outliers have expression profiles like scaled Bernoulli variables;
the scaling represents the size of the non-zero counts, while the probability $p$ is the proportion of non-zero counts.
The CV^2^ of such a variable is equal to $p^{-1}-1$, invariant with respect to scaling and decreasing with increasing $p$.
For any given proportion, this shows up on the CV^2^ plot as a horizontal line at a height depending on $p$.
If $p$ is high, you'll need a large mean (i.e., more scaling) to get the horizontal line above the technical trend.

<!--
21/259, and 67/469
-->

```{r, ref.label="cv2plotter"}
```

The improved method is even worse in this respect:

<!--
8/69
-->

```{r ref.label="icv2plotter"}
```


The log-variance method detects more.

<!--
127/127, and 240/351
-->

```{r, ref.label="logplotter"}
```

# Ranking of outliers

Another aspect of HVG detection methods is how they rank the discoveries.
This is important to the intepretation of the HVG list, if one were to have a look at which genes were driving heterogeneity.
The key point here is that methods based on the CV^2^ will favour genes with outliers above all others.
Let's simulate some counts:

```{r}
set.seed(100)
sim <- standardSetup(5000, 500)
counts <- sim$counts
is.spike <- sim$is.spike
```

Now, we add some HVGs - either with a single outlier, or with a range of variation in expression.
Arguably, the second to fourth examples are systematically more variable than the first example with the outlier.

```{r}
starting <- sum(is.spike)
rownames(counts) <- paste0("other", seq_len(nrow(counts)))
for (it in seq_len(10)) { 
    cur.mean <- it*10
    counts[starting + 1,] <- c(cur.mean*nsamples, integer(nsamples-1)) # outlier
    counts[starting + 2,] <- rnbinom(nsamples, mu=cur.mean, size=0.2) 
    counts[starting + 3,] <- rnbinom(nsamples, mu=cur.mean, size=0.5)
    counts[starting + 4,] <- rnbinom(nsamples, mu=cur.mean, size=1)
    rownames(counts)[starting + 1:4] <- paste0(it, ".", c("outlier", "5", "2", "1"))
    starting <- starting + 4
}
```

We look at the ranking of the HVGs from each method, as sorted by the biological component.
(The _p_-value sorting isn't as interesting in terms of what actually contributes to the heterogeneity in expression in absolute terms.)
The variance-of-logs method picks up the non-outliers first:

```{r}
lcounts <- log2(counts+1)
fit <- trendVar(lcounts[is.spike,], span=0.2)
ref <- decomposeVar(lcounts, fit)
head(ref[order(ref$bio, decreasing=TRUE),], 20)
```

Of course, the outliers will get picked up eventually, as the null is false and will eventually be rejected when you have enough cells.
Even so, the biological component for outliers from the variance-of-logs method is a lot smaller.
This allows them to be effectively removed by the additional `> 0.5` filtering.

```{r}
ref[grep("outlier", rownames(ref)),]
```

For the CV^2^ methods, the outliers dominate the ranking, regardless of whether we use the absolute difference or the fold-change.
This makes it difficult to prune them from the HVG list.
You could set an "expressed in at least N cells" requirement, but then that comes down to the choice of N.

```{r}
out <- technicalCV2(counts, is.spike, sf.cell=1, sf.spike=1)
head(out[order(out$cv2 - out$trend, decreasing=TRUE),], 10)
head(out[order(out$cv2/out$trend, decreasing=TRUE),], 10)
out <- improvedCV2(counts, is.spike, sf.cell=1, sf.spike=1)
head(out[order(out$cv2 - out$trend, decreasing=TRUE),], 10)
head(out[order(out$cv2/out$trend, decreasing=TRUE),], 10)
```

# Wrapping up

To conclude, the `technicalCV2` method just gives more noise at a FDR of 5%, without any appreciable increase in power.
This is probably a consequence of the odd trend fitting procedure and the unjustified statistical test, rather than anything to do with the CV^2^ itself.
From these results, it's clear that the choice of HVG detection method is between `improvedCV2` and `trendVar`.
They are fairly balanced though the former is better at detecting upregulated genes in rare populations and the latter is better at detecting downregulated genes.
`trendVar` is also less prone to detecting genes driven by outlier expression patterns.

```{r}
sessionInfo()
```

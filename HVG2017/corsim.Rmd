---
title: Some thoughts on testing for correlations
author: Aaron Lun
date: 18 February 2017
output:
  html_document:
    fig_caption: false 
---

```{r, echo=FALSE, results="hide"}
dir.create("figure-cor", showWarning=FALSE)
knitr::opts_chunk$set(error=FALSE, warning=FALSE, message=FALSE, fig.path="figure-cor/")
options(width=100)
```

# Why use a modified rho?

The modification simplifies things by allowing the same tie-free null distribution to be used for all genes.
It also means that we can get spuriously large correlations (which we would have been protected from, had we considered ties).
However, this is acceptable as we can let the error-control machinery deal with the possibility of such spuriously large values.
We also don't have to account for HVG identification in multiple testing here, because correlations are independent of the variance of the genes.

```{r, eval=FALSE}
library(scran)
set.seed(1023423)
ncells <- 100
null.dist <- correlateNull(ncells)
all.p <- list()
for (it in 1:10000) {
    x1 <- rpois(ncells, lambda=10)
    x2 <- rpois(ncells, lambda=20)
    rho2 <- cor(rank(x1, ties.method="random"), rank(x2, ties.method="random"), method="spearman")
    all.p[[it]] <- sum(null.dist >= rho2)/length(null.dist)
}
sum(unlist(all.p) <= 0.01)/10000
sum(unlist(all.p) <= 0.05)/10000
```

The idea is to mitigate dependence on explicit subpopulation identification for follow-up studies.
We identify strongly correlated genes first, then only need to check for subpopulations as a diagnostic.
This reduces the sensitivity of the analysis to ambiguity/uncertainty during subpopulation identification.
It's possible because validation requires genes, not subpopulations (as the current cells are destroyed), so we skip the middleman.

We can also check what happens with a design matrix.
Naively comparing against a null distribution of correlations that was constructed without considering the design will result in loss of control.
Rather, the null distribution should be compared to an appropriate null, as shown below.

```{r}
set.seed(12120)
design <- model.matrix(~factor(rep(1:5, 2)))
y <- matrix(rnorm(1000, mean=rep(1:5, 5), sd=2), ncol=10, byrow=TRUE)
null <- correlateNull(ncol(y))
out <- correlatePairs(y, design=design, null=null)
plot(log10(sort(out$p.value)/1:nrow(out)*nrow(out))) # wrong
null <- correlateNull(design=design, residuals=TRUE)
out <- correlatePairs(y, design=design, null=null, residuals=TRUE)
plot(log10(sort(out$p.value)/1:nrow(out)*nrow(out))) # right
```

# Statistical issues to be solved

## Problems with exchangeability

Generation of the null distribution assumes exchangeability of observations.
Specifically, there is the assumption that all observations are equally likely to receive any rank when performing the permutations.
This will not be the case in practice as some observations are more variable than others, depending on the mean-variance relationship.
As such, the variance of the correlations under the null will be underestimated: 

```{r}
means <- rep(c(5, 50), each=50)
disp <- rep(c(1, 0.1), each=50)
counts <- matrix(rnbinom(50000, mu=means, size=1/disp), byrow=TRUE, ncol=length(means))
counts <- t(t(counts)/means)
actual.cor <- cor(t(counts), method="spearman") 
pretend.cor <- correlateNull(100, iters=10000)
var(as.vector(actual.cor))
var(pretend.cor)
testing <- correlatePairs(counts, pretend.cor)
hist(testing$p.value) # fairly substantial loss of type I error control
```

I'm not sure that there's any way to get around this, without making some strong parametric assumptions about how the variance affects the ranking.
I guess we'll just have to suck it up - at least we get some level of protection from spurious correlations.

## Deficiencies with residuals

An obvious approach is to just estimate the correlations between residuals.
However, this is problematic, even in simple one-way layouts.
Consider a situation where you have two groups, with zeroes in almost all cells except for a few.
When you calculate residuals for each gene, you'll get blocks of values corresponding to the zeroes.
The exact value of these blocks with likely differ between groups; this can generate apparent correlations between genes.

```{r}
X <- model.matrix(~rep(LETTERS[1:2], each=50))
g1 <- integer(100)
g1[1] <- 100
g1[51] <- 1000
r1 <- lm.fit(X, g1)$residuals
g2 <- integer(100)
g2[2] <- 200
g2[52] <- 2000
r2 <- lm.fit(X, g2)$residuals
cor(r1, r2, method="spearman")
```

The problem above is why we calculate correlations within each group.
However, this is not possible for complex designs where we need to know the exact effect of each nuisance term on expression (and thus the rank).
Consider a real-valued covariate of 1:100 for 100 cells, where the count for the last cell is unity in each of two genes, and zeroes everywhere else.
You'll get correlations of 1 because the residual effects will be negative for the zeros.
This seems unavoidable; after all, the likelihood of obtaining a zero does change across cells, given the changes in the fitted value you want to correct for.

Don't bother trying to fit a linear model to the ranks, either.
I thought it would be a generalization of the definition of Spearman's (Pearson's on ranks).
However, there's no guarantee that unevenly-spaced covariates (or factors, for that matter) will make sense when fitted to ranks.

# Wrapping up

```{r}
sessionInfo()
```
